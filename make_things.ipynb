{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hangman import hangman, get_dictionary\n",
    "import wordfreq\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "# Makes the dictionary with the word frequencies\n",
    "big_dictionary = get_dictionary(\"words.txt\")\n",
    "\n",
    "# Convert to a dictionary with higher precision\n",
    "freq_dict = {}\n",
    "for word in big_dictionary:\n",
    "    weight = Decimal(wordfreq.word_frequency(word, \"en\", wordlist='small', minimum=0.0))\n",
    "    if weight > 0.0 and len(word) > 1:\n",
    "        freq_dict[word] = float(weight)  # Store as float to ensure JSON compatibility\n",
    "\n",
    "# Write it to a JSON file with high precision\n",
    "with open('webppl/word_freq.json', 'w') as f:\n",
    "    json.dump(freq_dict, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the letter frequencies from freq_dict \n",
    "\n",
    "letter_freq = {}\n",
    "for word in freq_dict:\n",
    "    for letter in word:\n",
    "        if letter in letter_freq:\n",
    "            letter_freq[letter] += freq_dict[word]\n",
    "        else:\n",
    "            letter_freq[letter] = freq_dict[word]\n",
    "            \n",
    "#normalize it \n",
    "total = sum(letter_freq.values())\n",
    "for letter in letter_freq:\n",
    "    letter_freq[letter] /= total\n",
    "    \n",
    "# Write it to a JSON file with high precision\n",
    "with open('webppl/letter_freq.json', 'w') as f:\n",
    "    json.dump(letter_freq, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" turn csv into data of the form \n",
    "\n",
    "var partial = [\"_\", \"o\", \"_\", \"_\", \"e\", \"_\", \"_\", \"_\", \"_\"]\n",
    "var in_letters = [\"o\", \"e\"]\n",
    "var not_in_letters = [\"s\"]\n",
    "var previousGuesses = in_letters.concat(not_in_letters)\n",
    "\n",
    "var data = [\n",
    "  {\n",
    "    previousGuesses: previousGuesses,\n",
    "    actualGuess: \"l\",\n",
    "    partialWordPattern: partial,\n",
    "    word: \"wonderful\"\n",
    "  },\n",
    "]\n",
    "\n",
    "\n",
    "where each guess is piece of data. each row of the csv is a series of guesses eg. \n",
    "8\tcalendar\te\tt \ta\tl\tn\ti\to\ts\tr\tc\td\t\n",
    "\"\"\" \n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Define the input CSV file path\n",
    "\n",
    "def make_data_from_csv(csv_file_path, data_file_path):\n",
    "\n",
    "    # Helper function to update the partial word pattern\n",
    "    def update_partial(partial, word, guess):\n",
    "        return [char if char == guess or char in partial else \"_\" for char in word]\n",
    "\n",
    "    # Initialize variables\n",
    "    output_data = []\n",
    "\n",
    "    # Read the CSV file\n",
    "    with open(csv_file_path, \"r\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=\"\\t\")\n",
    "        #skip the first row\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            row = row[0].split(\",\")\n",
    "            \n",
    "            if len(row) < 4:\n",
    "                continue\n",
    "            if row[0] == \"\":\n",
    "                continue\n",
    "            # Parse the data from the row\n",
    "            \n",
    "            step_number, word, *guesses = row\n",
    "            \n",
    "            #clean up the whitespace or commas\n",
    "            word = word.strip()\n",
    "            guesses = [guess.strip() for guess in guesses]\n",
    "            guesses = [guess for guess in guesses if guess != \"\"]\n",
    "            \n",
    "            \n",
    "            step_number = int(step_number)\n",
    "\n",
    "            # Initialize variables for this row\n",
    "            partial = [\"_\" for _ in word]\n",
    "            in_letters = []\n",
    "            not_in_letters = []\n",
    "\n",
    "            # Process each guess in the row\n",
    "            for i, guess in enumerate(guesses):\n",
    "               \n",
    "                if guess in word:\n",
    "                    in_letters.append(guess)\n",
    "                    partial = update_partial(partial, word, guess)\n",
    "                else:\n",
    "                    not_in_letters.append(guess)\n",
    "\n",
    "                previous_guesses = in_letters + not_in_letters\n",
    "\n",
    "                # Create the data point for this guess\n",
    "                data_point = {\n",
    "                    \"previousGuesses\": previous_guesses,\n",
    "                    \"actualGuess\": guess,\n",
    "                    \"partialWordPattern\": partial.copy(),\n",
    "                    \"word\": word\n",
    "                }\n",
    "\n",
    "                output_data.append(data_point)\n",
    "\n",
    "  \n",
    "    with open(data_file_path, \"w\") as output_file:\n",
    "        json.dump(output_data, output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data_from_csv(\"dataset.csv\", \"webppl-model/data.js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate successful and unsuccessful guess data \n",
    "def make_successful_unsuccessful_data(data_file_path, successful_data_file_path, unsuccessful_data_file_path):\n",
    "    with open(data_file_path, \"r\") as data_file:\n",
    "        data = json.load(data_file)\n",
    "        \n",
    "    successful_data = [d for d in data if d[\"actualGuess\"] in d[\"word\"]]\n",
    "    unsuccessful_data = [d for d in data if d[\"actualGuess\"] not in d[\"word\"]]\n",
    "    \n",
    "    with open(successful_data_file_path, \"w\") as output_file:\n",
    "        json.dump(successful_data, output_file, indent=2)\n",
    "        \n",
    "    with open(unsuccessful_data_file_path, \"w\") as output_file:\n",
    "        json.dump(unsuccessful_data, output_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_successful_unsuccessful_data(\"webppl-model/data.js\", \"webppl-model/successful_data.js\", \"webppl-model/unsuccessful_data.js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
