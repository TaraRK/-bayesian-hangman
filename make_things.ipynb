{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hangman import hangman, get_dictionary\n",
    "import wordfreq\n",
    "import json\n",
    "from decimal import Decimal, getcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "big_dictionary = get_dictionary(\"words.txt\")\n",
    "\n",
    "freq_dict = {}\n",
    "for word in big_dictionary:\n",
    "    word = word.lower()\n",
    "    weight = Decimal(wordfreq.word_frequency(word, \"en\", wordlist='small', minimum=0.0))\n",
    "    if weight > 0.0 and len(word) > 1:\n",
    "        freq_dict[word] = float(weight)  \n",
    "\n",
    "with open('webppl-model/word_freq.json', 'w') as f:\n",
    "    json.dump(freq_dict, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "getcontext().prec = 50\n",
    "weight = Decimal(wordfreq.word_frequency(\"moonrise\", \"en\", wordlist='small', minimum=0.0))\n",
    "print(weight)\n",
    "print(weight > 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'webppl/letter_freq.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m letter \u001b[38;5;129;01min\u001b[39;00m letter_freq:\n\u001b[0;32m     12\u001b[0m     letter_freq[letter] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m total\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwebppl/letter_freq.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     15\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(letter_freq, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'webppl/letter_freq.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "letter_freq = {}\n",
    "for word in freq_dict:\n",
    "    for letter in word:\n",
    "        if letter in letter_freq:\n",
    "            letter_freq[letter] += freq_dict[word]\n",
    "        else:\n",
    "            letter_freq[letter] = freq_dict[word]\n",
    "            \n",
    "\n",
    "total = sum(letter_freq.values())\n",
    "for letter in letter_freq:\n",
    "    letter_freq[letter] /= total\n",
    "    \n",
    "with open('webppl/letter_freq.json', 'w') as f:\n",
    "    json.dump(letter_freq, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" turn csv into data of the form \n",
    "\n",
    "var partial = [\"_\", \"o\", \"_\", \"_\", \"e\", \"_\", \"_\", \"_\", \"_\"]\n",
    "var in_letters = [\"o\", \"e\"]\n",
    "var not_in_letters = [\"s\"]\n",
    "var previousGuesses = in_letters.concat(not_in_letters)\n",
    "\n",
    "var data = [\n",
    "  {\n",
    "    previousGuesses: previousGuesses,\n",
    "    actualGuess: \"l\",\n",
    "    partialWordPattern: partial,\n",
    "    word: \"wonderful\"\n",
    "  },\n",
    "]\n",
    "\n",
    "\n",
    "where each guess is piece of data. each row of the csv is a series of guesses eg. \n",
    "8\tcalendar\te\tt \ta\tl\tn\ti\to\ts\tr\tc\td\t\n",
    "\"\"\" \n",
    "import csv\n",
    "import json\n",
    "\n",
    "def make_data_from_csv(csv_file_path, data_file_path):\n",
    "   \n",
    "    def update_partial(partial, word, guess):\n",
    "        return [char if char == guess or char in partial else \"_\" for char in word]\n",
    "\n",
    "    output_data = []\n",
    "\n",
    "    with open(csv_file_path, \"r\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=\"\\t\")\n",
    "        next(csv_reader) \n",
    "        for row in csv_reader:\n",
    "            row = row[0].split(\",\")\n",
    "            \n",
    "            if len(row) < 4 or row[0] == \"\":\n",
    "                continue\n",
    "\n",
    "            step_number, word, *guesses = row\n",
    "            word = word.strip().lower()\n",
    "            broken_words = [\"moonrise\"]\n",
    "            if word in broken_words:\n",
    "                continue\n",
    "            guesses = [guess.strip() for guess in guesses if guess.strip()]\n",
    "\n",
    "        \n",
    "            partial = [\"_\" for _ in word]\n",
    "            in_letters = []\n",
    "            not_in_letters = []\n",
    "\n",
    "      \n",
    "            for i, guess in enumerate(guesses):\n",
    "                \n",
    "                data_point = {\n",
    "                    \"previousGuesses\": in_letters + not_in_letters,\n",
    "                    \"actualGuess\": guess,\n",
    "                    \"partialWordPattern\": partial.copy(), \n",
    "                    \"word\": word\n",
    "                }\n",
    "\n",
    "          \n",
    "                output_data.append(data_point)\n",
    "\n",
    "             \n",
    "                if guess in word:\n",
    "                    in_letters.append(guess)\n",
    "                    partial = update_partial(partial, word, guess)\n",
    "                else:\n",
    "                    not_in_letters.append(guess)\n",
    "\n",
    "  \n",
    "    with open(data_file_path, \"w\") as output_file:\n",
    "        json.dump(output_data, output_file, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data_from_csv(\"dataset.csv\", \"webppl-model/data.js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_successful_unsuccessful_data(data_file_path, successful_data_file_path, unsuccessful_data_file_path):\n",
    "    with open(data_file_path, \"r\") as data_file:\n",
    "        data = json.load(data_file)\n",
    "\n",
    "  \n",
    "    successful_data = [\n",
    "        {\n",
    "            \"previousGuesses\": d[\"previousGuesses\"],\n",
    "            \"actualGuess\": d[\"actualGuess\"],\n",
    "            \"partialWordPattern\": [char if char in d[\"previousGuesses\"] else \"_\" for char in d[\"word\"]],\n",
    "            \"word\": d[\"word\"]\n",
    "        }\n",
    "        for d in data if d[\"actualGuess\"] in d[\"word\"]\n",
    "    ]\n",
    "\n",
    "    unsuccessful_data = [\n",
    "        {\n",
    "            \"previousGuesses\": d[\"previousGuesses\"],\n",
    "            \"actualGuess\": d[\"actualGuess\"],\n",
    "            \"partialWordPattern\": [char if char in d[\"previousGuesses\"] else \"_\" for char in d[\"word\"]],\n",
    "            \"word\": d[\"word\"]\n",
    "        }\n",
    "        for d in data if d[\"actualGuess\"] not in d[\"word\"]\n",
    "    ]\n",
    "\n",
    "    with open(successful_data_file_path, \"w\") as output_file:\n",
    "        json.dump(successful_data, output_file, indent=2)\n",
    "\n",
    "    \n",
    "    with open(unsuccessful_data_file_path, \"w\") as output_file:\n",
    "        json.dump(unsuccessful_data, output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_successful_unsuccessful_data(\"webppl-model/data.js\", \"webppl-model/successful_data.js\", \"webppl-model/unsuccessful_data.js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def split_data_by_game_step(data_file_path, output_folder_path):\n",
    "    \"\"\"\n",
    "    Splits the game data into steps of the game (e.g., first guess, second guess) \n",
    "    and saves them as separate files.\n",
    "\n",
    "    Args:\n",
    "        data_file_path (str): Path to the input data file (JSON format).\n",
    "        output_folder_path (str): Path to the folder where step-wise files will be saved.\n",
    "\n",
    "    Output:\n",
    "        Saves separate JSON files for each step in the game.\n",
    "    \"\"\"\n",
    "    with open(data_file_path, \"r\") as data_file:\n",
    "        data = json.load(data_file)\n",
    "\n",
    "    \n",
    "    steps = {}\n",
    "\n",
    "    \n",
    "    for record in data:\n",
    "        step = len(record[\"previousGuesses\"]) + 1  \n",
    "        if step not in steps:\n",
    "            steps[step] = []\n",
    "        steps[step].append(record)\n",
    "\n",
    " \n",
    "    for step, guesses in steps.items():\n",
    "        output_file_path = f\"{output_folder_path}/step_{step}.json\"\n",
    "        with open(output_file_path, \"w\") as output_file:\n",
    "            json.dump(guesses, output_file, indent=2)\n",
    "\n",
    "    print(f\"Data successfully split into steps and saved in {output_folder_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split into steps and saved in webppl-model/data_steps.\n"
     ]
    }
   ],
   "source": [
    "split_data_by_game_step(\"webppl-model/data.js\", \"webppl-model/data_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data_by_word(data_file_path, output_folder_path):\n",
    "    \"\"\"\n",
    "    Splits the game data into steps of the game (e.g., first guess, second guess) \n",
    "    and saves them as separate files.\n",
    "\n",
    "    Args:\n",
    "        data_file_path (str): Path to the input data file (JSON format).\n",
    "        output_folder_path (str): Path to the folder where step-wise files will be saved.\n",
    "\n",
    "    Output:\n",
    "        Saves separate JSON files for each step in the game.\n",
    "    \"\"\"\n",
    "    with open(data_file_path, \"r\") as data_file:\n",
    "        data = json.load(data_file)\n",
    "\n",
    " \n",
    "    words = {}\n",
    "\n",
    "    for record in data:\n",
    "        word = record[\"word\"]\n",
    "        if word not in words:\n",
    "            words[word] = []\n",
    "        words[word].append(record)\n",
    "\n",
    "    for word, guesses in words.items():\n",
    "        output_file_path = f\"{output_folder_path}/{word}.json\"\n",
    "        with open(output_file_path, \"w\") as output_file:\n",
    "            json.dump(guesses, output_file, indent=2)\n",
    "\n",
    "    print(f\"Data successfully split into words and saved in {output_folder_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split into words and saved in webppl-model/data_words.\n"
     ]
    }
   ],
   "source": [
    "split_data_by_word(\"webppl-model/data.js\", \"webppl-model/data_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
