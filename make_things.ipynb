{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hangman import hangman, get_dictionary\n",
    "import wordfreq\n",
    "import json\n",
    "from decimal import Decimal, getcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Makes the dictionary with the word frequencies\n",
    "big_dictionary = get_dictionary(\"words.txt\")\n",
    "\n",
    "# Convert to a dictionary with higher precision\n",
    "freq_dict = {}\n",
    "for word in big_dictionary:\n",
    "    word = word.lower()\n",
    "    weight = Decimal(wordfreq.word_frequency(word, \"en\", wordlist='small', minimum=0.0))\n",
    "    if weight > 0.0 and len(word) > 1:\n",
    "        freq_dict[word] = float(weight)  # Store as float to ensure JSON compatibility\n",
    "\n",
    "# Write it to a JSON file with high precision\n",
    "with open('webppl-model/word_freq.json', 'w') as f:\n",
    "    json.dump(freq_dict, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "getcontext().prec = 50\n",
    "weight = Decimal(wordfreq.word_frequency(\"moonrise\", \"en\", wordlist='small', minimum=0.0))\n",
    "print(weight)\n",
    "print(weight > 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'webppl/letter_freq.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     letter_freq[letter] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m total\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Write it to a JSON file with high precision\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwebppl/letter_freq.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     18\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(letter_freq, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'webppl/letter_freq.json'"
     ]
    }
   ],
   "source": [
    "#get the letter frequencies from freq_dict \n",
    "\n",
    "letter_freq = {}\n",
    "for word in freq_dict:\n",
    "    for letter in word:\n",
    "        if letter in letter_freq:\n",
    "            letter_freq[letter] += freq_dict[word]\n",
    "        else:\n",
    "            letter_freq[letter] = freq_dict[word]\n",
    "            \n",
    "#normalize it \n",
    "total = sum(letter_freq.values())\n",
    "for letter in letter_freq:\n",
    "    letter_freq[letter] /= total\n",
    "    \n",
    "# Write it to a JSON file with high precision\n",
    "with open('webppl/letter_freq.json', 'w') as f:\n",
    "    json.dump(letter_freq, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" turn csv into data of the form \n",
    "\n",
    "var partial = [\"_\", \"o\", \"_\", \"_\", \"e\", \"_\", \"_\", \"_\", \"_\"]\n",
    "var in_letters = [\"o\", \"e\"]\n",
    "var not_in_letters = [\"s\"]\n",
    "var previousGuesses = in_letters.concat(not_in_letters)\n",
    "\n",
    "var data = [\n",
    "  {\n",
    "    previousGuesses: previousGuesses,\n",
    "    actualGuess: \"l\",\n",
    "    partialWordPattern: partial,\n",
    "    word: \"wonderful\"\n",
    "  },\n",
    "]\n",
    "\n",
    "\n",
    "where each guess is piece of data. each row of the csv is a series of guesses eg. \n",
    "8\tcalendar\te\tt \ta\tl\tn\ti\to\ts\tr\tc\td\t\n",
    "\"\"\" \n",
    "import csv\n",
    "import json\n",
    "\n",
    "def make_data_from_csv(csv_file_path, data_file_path):\n",
    "    # Helper function to update the partial word pattern\n",
    "    def update_partial(partial, word, guess):\n",
    "        return [char if char == guess or char in partial else \"_\" for char in word]\n",
    "\n",
    "    # Initialize variables\n",
    "    output_data = []\n",
    "\n",
    "    # Read the CSV file\n",
    "    with open(csv_file_path, \"r\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=\"\\t\")\n",
    "        next(csv_reader)  # Skip the first row (header)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            row = row[0].split(\",\")\n",
    "            \n",
    "            if len(row) < 4 or row[0] == \"\":\n",
    "                continue\n",
    "\n",
    "            # Parse the data from the row\n",
    "            step_number, word, *guesses = row\n",
    "            word = word.strip().lower()\n",
    "            broken_words = [\"moonrise\"]\n",
    "            if word in broken_words:\n",
    "                continue\n",
    "            guesses = [guess.strip() for guess in guesses if guess.strip()]\n",
    "\n",
    "            # Initialize variables for this row\n",
    "            partial = [\"_\" for _ in word]\n",
    "            in_letters = []\n",
    "            not_in_letters = []\n",
    "\n",
    "            # Process each guess in the row\n",
    "            for i, guess in enumerate(guesses):\n",
    "                # Create the data point BEFORE applying the current guess\n",
    "                data_point = {\n",
    "                    \"previousGuesses\": in_letters + not_in_letters,\n",
    "                    \"actualGuess\": guess,\n",
    "                    \"partialWordPattern\": partial.copy(),  # Partial before applying the guess\n",
    "                    \"word\": word\n",
    "                }\n",
    "\n",
    "                # Append the data point\n",
    "                output_data.append(data_point)\n",
    "\n",
    "                # Update the partial and letter lists AFTER creating the data point\n",
    "                if guess in word:\n",
    "                    in_letters.append(guess)\n",
    "                    partial = update_partial(partial, word, guess)\n",
    "                else:\n",
    "                    not_in_letters.append(guess)\n",
    "\n",
    "    # Write the output data to a JSON file\n",
    "    with open(data_file_path, \"w\") as output_file:\n",
    "        json.dump(output_data, output_file, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data_from_csv(\"dataset.csv\", \"webppl-model/data.js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate successful and unsuccessful guess data\n",
    "def make_successful_unsuccessful_data(data_file_path, successful_data_file_path, unsuccessful_data_file_path):\n",
    "    with open(data_file_path, \"r\") as data_file:\n",
    "        data = json.load(data_file)\n",
    "\n",
    "    # Filter successful and unsuccessful guesses\n",
    "    successful_data = [\n",
    "        {\n",
    "            \"previousGuesses\": d[\"previousGuesses\"],\n",
    "            \"actualGuess\": d[\"actualGuess\"],\n",
    "            \"partialWordPattern\": [char if char in d[\"previousGuesses\"] else \"_\" for char in d[\"word\"]],\n",
    "            \"word\": d[\"word\"]\n",
    "        }\n",
    "        for d in data if d[\"actualGuess\"] in d[\"word\"]\n",
    "    ]\n",
    "\n",
    "    unsuccessful_data = [\n",
    "        {\n",
    "            \"previousGuesses\": d[\"previousGuesses\"],\n",
    "            \"actualGuess\": d[\"actualGuess\"],\n",
    "            \"partialWordPattern\": [char if char in d[\"previousGuesses\"] else \"_\" for char in d[\"word\"]],\n",
    "            \"word\": d[\"word\"]\n",
    "        }\n",
    "        for d in data if d[\"actualGuess\"] not in d[\"word\"]\n",
    "    ]\n",
    "\n",
    "    # Save successful guesses\n",
    "    with open(successful_data_file_path, \"w\") as output_file:\n",
    "        json.dump(successful_data, output_file, indent=2)\n",
    "\n",
    "    # Save unsuccessful guesses\n",
    "    with open(unsuccessful_data_file_path, \"w\") as output_file:\n",
    "        json.dump(unsuccessful_data, output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_successful_unsuccessful_data(\"webppl-model/data.js\", \"webppl-model/successful_data.js\", \"webppl-model/unsuccessful_data.js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
